@startuml CA4_C2_Container_Diagram

title CA4 – C4 Level 2 Container Diagram\nEdge Processing System (Local Processor + Kafka + Worker)

skinparam shadowing false
skinparam componentStyle rectangle
skinparam defaultFontName Arial
skinparam wrapWidth 220
skinparam maxMessageSize 140

' -------------------------------------------------
' ACTORS
' -------------------------------------------------
actor "Colab Notebook User" as COLAB_USER
actor "Developer / Operator" as DEV_USER

' -------------------------------------------------
' EXTERNAL SYSTEMS
' -------------------------------------------------
rectangle "Colab GPU Metadata Producer\n(Google Colab System)" as COLAB_SYS

rectangle "Data Platform\nMongo (DB=ca4, coll=gpu_metadata)\n+ Optional S3 Archive" as DATA_PLATFORM

rectangle "Observability Platform\n(Prometheus + Loki + Grafana)" as OBS_PLATFORM

' -------------------------------------------------
' SYSTEM UNDER DESIGN: CA4 EDGE PROCESSING SYSTEM
' -------------------------------------------------
package "CA4 Edge Processing System\n(Local Processor + AWS VPC K3s/Kafka/Worker)" as CA4_SYS {

  rectangle "Processor API (Local)\nFastAPI / Python\nRuns on Dev Laptop\nPublishes to Kafka via SSH + port-forward" as API_LOCAL

  ' Optional future in-cluster Processor
  rectangle "Processor API (Edge – optional)\nFastAPI / Python\nK3s Deployment + Service\n(Not deployed in current CA4)" as API_EDGE <<future>>

  rectangle "Kafka Cluster\nApache Kafka\nK3s StatefulSet\nTopic: gpu-metadata" as KAFKA

  rectangle "Worker\nPython Service\nK3s Deployment (app=worker)\nKafka Consumer for gpu-metadata" as WORKER

  rectangle "Bastion Host\nEC2 / SSH Jumpbox\nTunnels to K3s, Kafka, Grafana" as BASTION

  rectangle "K3s Control Plane\nKubernetes API\nEdge Node Group" as K3S_CTRL
}

' -------------------------------------------------
' RELATIONSHIPS – DATA FLOW AND CONTROL
' -------------------------------------------------

' User -> Colab system
COLAB_USER --> COLAB_SYS : Run GPU/TPU notebook\nand metadata extraction code

' Colab -> Local Processor in CA4 system
COLAB_SYS --> API_LOCAL : POST /metadata\n(JSON over HTTPS\nvia ngrok tunnel in dev)

' Local Processor -> Kafka inside CA4 system
API_LOCAL --> KAFKA : Publish gpu-metadata events\n(through SSH + port-forward\nbootstrap=localhost:9092)

' Optional future direct Colab -> Edge API path
COLAB_SYS --> API_EDGE : (Future) POST /metadata\n(VPN / Ingress)
API_EDGE --> KAFKA : (Future) Publish gpu-metadata\n(in-cluster, no tunneling)

' Kafka -> Worker
KAFKA --> WORKER : Consume gpu-metadata\n(Kafka protocol, consumer group=worker)

' CA4 system -> Data Platform
WORKER --> DATA_PLATFORM : Write transformed metadata docs\nMongo: ca4.gpu_metadata\n(Optional: archive to S3)

' Observability flows (high level)
CA4_SYS --> OBS_PLATFORM : Metrics and logs\n(API, Kafka, Worker, DB exporters)

' Dev / operator control interactions
DEV_USER --> BASTION : SSH tunnel\nssh -L ... (bastion)
BASTION --> K3S_CTRL : Access K3s API\n(kubectl, deployments)
BASTION --> KAFKA : Access Kafka brokers\n(topic inspection, debugging)
DEV_USER --> OBS_PLATFORM : View Grafana dashboards\nvia tunneled access

@enduml
